<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Recurrent Models of Visual Attention - Tender is the night.</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Tender is the night."><meta name="msapplication-TileImage" content="/img/francis.ico"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Tender is the night."><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="背景和动机人类在观察物体的时候，在总体对目标进行把握的时候，通常不是将目光放到整个物体上，而是按照一定的次序对物体进行扫描，有选择地将注意力集中到某些位置上，然后将这些区域信息进行汇总处理。通过不同时间下不同位置信息的组合，建立场景的表征，来指导眼睛的关注点。这样就将计算资源集中到了有价值的信息上，从而节省了带宽。"><meta property="og:type" content="blog"><meta property="og:title" content="Recurrent Models of Visual Attention"><meta property="og:url" content="https://blog.deqiang.wang/2021/05/13/LWYD-Attention/"><meta property="og:site_name" content="Tender is the night."><meta property="og:description" content="背景和动机人类在观察物体的时候，在总体对目标进行把握的时候，通常不是将目光放到整个物体上，而是按照一定的次序对物体进行扫描，有选择地将注意力集中到某些位置上，然后将这些区域信息进行汇总处理。通过不同时间下不同位置信息的组合，建立场景的表征，来指导眼睛的关注点。这样就将计算资源集中到了有价值的信息上，从而节省了带宽。"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://i.loli.net/2021/05/13/IrtRnakhpWxFOBD.png"><meta property="og:image" content="https://pic1.zhimg.com/80/v2-a1b4b3765e0f451258d579b9fdaffd38_1440w.jpg"><meta property="og:image" content="https://i.loli.net/2021/05/13/FL9tA2MKTgjbCc4.png"><meta property="og:image" content="https://i.loli.net/2021/05/13/q92g6LOJfnePEoB.png"><meta property="og:image" content="https://i.loli.net/2021/05/13/4Tc6IZtuBKFpOUX.png"><meta property="article:published_time" content="2021-05-13T06:22:35.000Z"><meta property="article:modified_time" content="2022-07-07T02:59:50.596Z"><meta property="article:author" content="Francis"><meta property="article:tag" content="深度学习"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://i.loli.net/2021/05/13/IrtRnakhpWxFOBD.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.deqiang.wang/2021/05/13/LWYD-Attention/"},"headline":"Recurrent Models of Visual Attention","image":["https://i.loli.net/2021/05/13/IrtRnakhpWxFOBD.png","https://pic1.zhimg.com/80/v2-a1b4b3765e0f451258d579b9fdaffd38_1440w.jpg","https://i.loli.net/2021/05/13/FL9tA2MKTgjbCc4.png","https://i.loli.net/2021/05/13/q92g6LOJfnePEoB.png","https://i.loli.net/2021/05/13/4Tc6IZtuBKFpOUX.png"],"datePublished":"2021-05-13T06:22:35.000Z","dateModified":"2022-07-07T02:59:50.596Z","author":{"@type":"Person","name":"Francis"},"description":"背景和动机人类在观察物体的时候，在总体对目标进行把握的时候，通常不是将目光放到整个物体上，而是按照一定的次序对物体进行扫描，有选择地将注意力集中到某些位置上，然后将这些区域信息进行汇总处理。通过不同时间下不同位置信息的组合，建立场景的表征，来指导眼睛的关注点。这样就将计算资源集中到了有价值的信息上，从而节省了带宽。"}</script><link rel="canonical" href="https://blog.deqiang.wang/2021/05/13/LWYD-Attention/"><link rel="icon" href="/img/francis.ico"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/monokai.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?330fdb4750eb9751bd56abdec3e28579";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-161981280-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-161981280-1');</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.2"></head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logofrancis.png" alt="Tender is the night." height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-05-13T06:22:35.000Z" title="2021-5-13 14:22:35">2021-05-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-07T02:59:50.596Z" title="2022-7-7 10:59:50">2022-07-07</time></span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span><span class="level-item">10 minutes read (About 1427 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Recurrent Models of Visual Attention</h1><div class="content"><h3 id="背景和动机"><a href="#背景和动机" class="headerlink" title="背景和动机"></a>背景和动机</h3><p>人类在观察物体的时候，在总体对目标进行把握的时候，通常不是将目光放到整个物体上，而是按照一定的次序对物体进行扫描，有选择地将注意力集中到某些位置上，然后将这些区域信息进行汇总处理。通过不同时间下不同位置信息的组合，建立场景的表征，来指导眼睛的关注点。这样就将计算资源集中到了有价值的信息上，从而节省了带宽。</p>
<span id="more"></span>

<h3 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h3><p>将Attention看成是由目标引导的一个序列决策过程，鉴于当时条件的限制及CNN发展的阶段，采用 RNN 模型建模，然后通过 Attention及强化算法来决定序列各阶段模型该看图片的哪个 patch，来获取任务相关的关键信息，过滤无关信息，这样模型计算量与图片的输入尺寸相互独立，从而减少计算量。强化学习算法主要用来模拟与环境交互，每一时间点智能体只根据限制频域或空域的范围提取信息，它自主选择感知域，并通过奖惩机制获得反馈，并实现收益的最大化。</p>
<p>1.模型</p>
<p><img src="https://i.loli.net/2021/05/13/IrtRnakhpWxFOBD.png" alt=""></p>
<p>各模块介绍如下</p>
<p>Glimpse Sensor<br>结构如图A所示，以位置信息 <div>$l_{t-1}$</div>为中心，长宽为<div> $w$</div> 的倍数提取图像 patch，即 attention region，将提取的区域归一化到<div> $w * w$</div> 大小，拼接得到输入<div> $\rho\left(x_{t}, l_{t-1}\right)$ </div>，从而把不同层次的信息组合了起来，并且起到减少计算量和噪声影响的作用。</p>
<p>Glimpse Network<br> 结构如图B所示，输入层次信息<div>$\rho\left(x_{t}, l_{t-1}\right)$</div> 后通过网络<div> $f_{g}\left(\theta_{g}^{0}\right)$</div> 得到潜在层次信息，位置信息<div>$l_{t-1}$</div>通过网络 <div>$f_{g}\left(\theta_{g}^{1}\right)$ </div>得到潜在位置信息，将两种信息经过网络<div> $f_{g}\left(\theta_{g}^{2}\right)$ </div>处理得到RNN的输入向量<div> $g_{t}$ </div>。</p>
<p>Action and Location Extractor</p>
<p> 结构如下所示，</p>
<p><img src="https://pic1.zhimg.com/80/v2-a1b4b3765e0f451258d579b9fdaffd38_1440w.jpg" alt=""></p>
<p>输入信息<div> $g_{t}$ </div>和前一阶段历史信息<div> $h_{t-1}$ </div>经由RNN得到下一阶段输入的隐藏层信息，而隐藏层信息通过不完全可观察马尔科夫决策过程(POMDP)得到下一动作<div> $a_{t}$ </div>和下一阶段的位置信息 <div>$l_{t}$</div> 。</p>
<p>整体结构：</p>
<p><img src="https://i.loli.net/2021/05/13/FL9tA2MKTgjbCc4.png" alt=""></p>
<p>2.训练</p>
<p><img src="https://i.loli.net/2021/05/13/q92g6LOJfnePEoB.png" alt=""></p>
<p>训练目标：使得总奖励最大</p>
<div>
$$
J(\theta)=\mathbb{E}_{p} p\left(s_{1: T} ; \theta\right)\left[\sum_{t=1}^{T} r_{t}\right]=\mathbb{E}_{p\left(s_{1: T} ; \theta\right)}[R]
$$
</div>
REINFORCE方法：取经验平均求解（样本近似）的方法来逼近梯度:
<div>
$$
\nabla_{\theta} J=\sum_{t=1}^{T} \mathbb{E}_{p\left(s_{1: T} ; \theta\right)}\left[\nabla_{\theta} \log \pi\left(u_{t} \mid s_{1: t} ; \theta\right) R\right] \approx \frac{1}{M} \sum_{i=1}^{M} \sum_{t=1}^{T} \nabla_{\theta} \log \pi\left(u_{t}^{i} \mid s_{1: t}^{i} ; \theta\right) R^{i}
$$
</div>
反向传播训练：通过REINFORCE得到 <div>$f_{a}$</div> 和<div> $f_{l}$ </div>的梯度信息。然后反向依次训练RNN, Glimpse Network。对于分类问题，由于 <div>$a_{T}$ </div>是确定，最大化<div> $\log \pi\left(a_{T} \mid s_{1: T} ; \theta\right)$</div>,通过优化 <div>$f_{a}$</div> 的交叉熵得到梯度，反向训练模型。

<h3 id="理论依据"><a href="#理论依据" class="headerlink" title="理论依据"></a>理论依据</h3><p>1.RNN&amp;HMM</p>
<p>整个模型过程可以看做是一个局部马尔科夫决策过程。每个阶段的动作和位置只与上一阶段的动作和位置有关，从而控制模型的参数和计算量，使之摆脱输入图像的大小的约束。展开RNN结构，以时间为序，整个过程可表示为<div> $s_{1: t}=x_{1}, l_{1}, a_{1}, \ldots, x_{t-1}, l_{t-1}, a_{t-1}, x_{t}$</div>。根据上一阶段的动作 <div>$a_{t}$ </div>和位置<div> $l_{t-1}$</div>, 从输入图像提取出信息，通过模型网络，输出特征信息。按照个人理解，这一方法可行性是基于RNN把上下文状态在每一个时间点进行更新，并保存下来，具有天然的马尔科夫特性，并且具有非线性拟合的优势。</p>
<p>2.强化学习</p>
<p>在执行一个动作之后， agent会收到一个环境中得到的新的视觉观祭 <div>$\mathrm{x}<em>{\mathrm{t}+1}$</div> 和一个奖励信号<div>$\mathrm{r}</em>{\mathrm{t}+1}$</div> 。在目标识别场景中，如果分类正确，就奖励1分，否则奖励就设置为0，从而利用POMDP决定出下一阶段的动作 <div>$a_{t}$</div> 和位置 <div>$l_{t}$</div> 。奖惩机制为agent提供额外信息辅助，来决定如何行动和如何最有效的布置感知器。</p>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="https://i.loli.net/2021/05/13/4Tc6IZtuBKFpOUX.png" alt=""></p>
<p>本文描述了一个端到端的优化序列，能够直接训练模型，最大化一个性能衡量，依赖于该模型在整个任务上所做的决策。按照时间顺序处理输入，一次在一张图像中处理不同的位置，逐渐的将这些部分的信息结合起来，来建立一个该场景或者环境的动态间隔表示。利用反向传播来训练神经网络的成分和策略梯度来解决控制问题的不可微性。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Recurrent Models of Visual Attention</p><p><a href="https://blog.deqiang.wang/2021/05/13/LWYD-Attention/">https://blog.deqiang.wang/2021/05/13/LWYD-Attention/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Francis</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2021-05-13</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2022-07-07</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=5e7cd1515b1431001927bbd8&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/img/alipay.png" alt="Alipay"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/img/weixinpay.png" alt="Wechat"></span></a><a class="button donate" href="https://www.buymeacoffee.com/NRy52OH" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="idealdestructor@gmail.com"><input type="hidden" name="currency_code" value="USD"></form></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2021/05/15/HYSL-%E5%BF%AB%E6%89%8B%E6%8A%80%E6%9C%AF%E5%98%89%E5%B9%B4%E5%8D%8E/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">快手技术嘉年华</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/05/13/LWYD-Long-tail/"><span class="level-item">Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect NIPS，2020</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="content" id="valine-thread"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script><script>new Valine({
            el: '#valine-thread' ,
            appId: "Df8zpeaXIjXp13rliBbmXmbi-gzGzoHsz",
            appKey: "pnd6tjS2MVYnYeacKIhQFINI",
            
            avatar: "robohash",
            
            meta: ["nick","mail","link"],
            pageSize: 10,
            lang: "en",
            
            highlight: true,
            
            
            
            
            
            requiredFields: [],
        });</script></div></div></div><!--!--><!--!--></div></div></section><footer class="footer"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/aplayer/1.10.1/APlayer.min.css" integrity="sha512-CIYsJUa3pr1eoXlZFroEI0mq0UIMUqNouNinjpCkSWo3Bx5NRlQ0OuC6DtEB/bDqUWnzXc1gs2X/g52l36N5iw==" crossorigin="anonymous" referrerpolicy="no-referrer"><script src="https://cdnjs.cloudflare.com/ajax/libs/aplayer/1.10.1/APlayer.min.js"></script><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logofrancis.png" alt="Tender is the night." height="28"></a><p class="is-size-7"><span>&copy; 2022 Francis</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div id="aplayer"></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="LeetCode" href="https://leetcode-cn.com/u/idealdestructor/"><i class="fas fa-terminal"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Scholar" href="https://scholar.google.com/citations?hl=zh-CN&amp;view_op=list_works&amp;gmla=AJsN-F5BJwq0y_k5LvIAnx2w8-J7gQF5XRICqZuNECnwqg8hFisRyGzQ-iCt0Uw0Xbt9hCGedhwcIc_r4BElnmfIs-HBrrA5mzXJblpTXOVNeNsJtzencFk&amp;user=Ykem_e8AAAAJ"><i class="fas fa-graduation-cap"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/idealdestructor"><i class="fab fa-github"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Email" href="mailto:hi@mail.deqiang.wang"><i class="fa fa-envelope"></i></a></p></div></div></div></div><script src="https://deqiang.wang/aplayer.js"></script></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>